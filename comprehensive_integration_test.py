#!/usr/bin/env python3
"""
Claude Echo æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿç»¼åˆé›†æˆæµ‹è¯•
Integration Agent - ç³»ç»Ÿé›†æˆå’Œç«¯åˆ°ç«¯æµ‹è¯•

æµ‹è¯•èŒƒå›´ï¼š
1. å­¦ä¹ ç³»ç»Ÿç»„ä»¶é›†æˆæµ‹è¯•
2. å¤šAgentåä½œæµ‹è¯• 
3. è¯­éŸ³å­¦ä¹ å¼•æ“æµ‹è¯•
4. Claude Codeé€‚é…å™¨é›†æˆæµ‹è¯•
5. ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•
6. æ€§èƒ½å’Œç¨³å®šæ€§æµ‹è¯•
7. æ•°æ®éš”ç¦»å’Œå®‰å…¨æ€§æµ‹è¯•
"""

import asyncio
import time
import sys
import json
import uuid
import tempfile
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

# Mock setup for dependencies
class MockLogger:
    def info(self, msg): print(f"[INFO] {msg}")
    def error(self, msg): print(f"[ERROR] {msg}")
    def warning(self, msg): print(f"[WARNING] {msg}")
    def debug(self, msg): print(f"[DEBUG] {msg}")
    def bind(self, **kwargs): return self

sys.path.insert(0, str(Path(__file__).parent / "src"))

# Mock external dependencies
mock_modules = ['loguru', 'whisper', 'pyttsx3', 'pyaudio', 'numpy', 'scipy', 
                'librosa', 'watchdog', 'watchdog.observers', 'watchdog.events', 
                'pydantic', 'cryptography', 'cryptography.fernet']

for module in mock_modules:
    if module not in sys.modules:
        if module == 'loguru':
            sys.modules[module] = type(sys)('mock_loguru')
            sys.modules[module].logger = MockLogger()
        elif module == 'pydantic':
            class MockBaseModel:
                def __init__(self, **kwargs):
                    for k, v in kwargs.items():
                        setattr(self, k, v)
                def dict(self): return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}
            sys.modules[module] = type(sys)('mock_pydantic')
            sys.modules[module].BaseModel = MockBaseModel
        elif module == 'cryptography.fernet':
            class MockFernet:
                def __init__(self, key): self.key = key
                @staticmethod
                def generate_key(): return b'test_key_1234567890'
                def encrypt(self, data): return f"encrypted_{data}".encode()
                def decrypt(self, data): return data.decode().replace("encrypted_", "").encode()
            sys.modules[module] = type(sys)('mock_fernet')
            sys.modules[module].Fernet = MockFernet
        elif module == 'cryptography':
            sys.modules[module] = type(sys)('mock_cryptography')
        else:
            sys.modules[module] = type(sys)(f'mock_{module}')


class TestResult(Enum):
    PASS = "PASS"
    FAIL = "FAIL"
    SKIP = "SKIP"
    WARNING = "WARNING"


@dataclass
class TestCase:
    name: str
    result: TestResult
    details: str
    execution_time: float
    category: str
    severity: str = "normal"  # normal, critical, warning


class ComprehensiveIntegrationTester:
    """ç»¼åˆé›†æˆæµ‹è¯•å™¨ - éªŒè¯å®Œæ•´çš„æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿé›†æˆ"""
    
    def __init__(self):
        self.test_results: List[TestCase] = []
        self.start_time = time.time()
        self.test_data_dir = Path(tempfile.mkdtemp(prefix="claude_echo_test_"))
        self.performance_metrics: Dict[str, float] = {}
        
        # æµ‹è¯•ç»Ÿè®¡
        self.stats = {
            'total_tests': 0,
            'passed_tests': 0,
            'failed_tests': 0,
            'skipped_tests': 0,
            'warning_tests': 0
        }
        
        print(f"âœ… æµ‹è¯•ç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼Œæµ‹è¯•æ•°æ®ç›®å½•: {self.test_data_dir}")
    
    def log_test(self, name: str, result: TestResult, details: str, 
                 category: str, execution_time: float = 0, severity: str = "normal"):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        test_case = TestCase(
            name=name,
            result=result,
            details=details,
            execution_time=execution_time,
            category=category,
            severity=severity
        )
        
        self.test_results.append(test_case)
        self.stats['total_tests'] += 1
        self.stats[f'{result.value.lower()}_tests'] += 1
        
        # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
        icons = {
            TestResult.PASS: "âœ…",
            TestResult.FAIL: "âŒ", 
            TestResult.SKIP: "â­ï¸",
            TestResult.WARNING: "âš ï¸"
        }
        
        severity_prefix = "ğŸ”´" if severity == "critical" else ""
        icon = icons.get(result, "â“")
        
        print(f"{severity_prefix}{icon} [{category}] {name}: {details} ({execution_time:.3f}s)")
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰é›†æˆæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ Claude Echo æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿç»¼åˆé›†æˆæµ‹è¯•")
        print("=" * 80)
        
        # æµ‹è¯•åˆ†ç±»å’Œé¡ºåº
        test_categories = [
            ("æ ¸å¿ƒæ¶æ„é›†æˆ", self.test_core_architecture_integration),
            ("å­¦ä¹ æ•°æ®ç®¡ç†", self.test_learning_data_management),
            ("è¯­éŸ³å­¦ä¹ ç³»ç»Ÿ", self.test_speech_learning_integration),
            ("Agentç³»ç»Ÿåä½œ", self.test_agent_system_collaboration),
            ("Claude Codeé›†æˆ", self.test_claude_code_integration),
            ("ç«¯åˆ°ç«¯å·¥ä½œæµ", self.test_end_to_end_workflows),
            ("å¤šç”¨æˆ·å¹¶å‘", self.test_multi_user_scenarios),
            ("æ€§èƒ½å’Œç¨³å®šæ€§", self.test_performance_and_stability),
            ("å®‰å…¨å’Œéšç§", self.test_security_and_privacy),
            ("é”™è¯¯å¤„ç†", self.test_error_handling_and_recovery)
        ]
        
        for category_name, test_func in test_categories:
            print(f"\nğŸ” å¼€å§‹æµ‹è¯•ç±»åˆ«: {category_name}")
            print("-" * 60)
            
            try:
                await test_func()
            except Exception as e:
                self.log_test(
                    f"{category_name} - æµ‹è¯•æ‰§è¡Œ",
                    TestResult.FAIL,
                    f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                    category_name,
                    0,
                    "critical"
                )
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
    
    async def test_core_architecture_integration(self):
        """æµ‹è¯•æ ¸å¿ƒæ¶æ„é›†æˆ"""
        category = "æ ¸å¿ƒæ¶æ„é›†æˆ"
        start_time = time.time()
        
        # æµ‹è¯•äº‹ä»¶ç³»ç»Ÿé›†æˆ
        try:
            from core.event_system import EventSystem, Event, EventPriority
            
            event_system = EventSystem()
            await event_system.initialize()
            
            # æµ‹è¯•äº‹ä»¶å‘å¸ƒå’Œè®¢é˜…
            events_received = []
            def test_handler(event):
                events_received.append(event.event_type)
            
            await event_system.subscribe("learning.*", test_handler)
            await event_system.emit(Event(
                event_type="learning.test_integration",
                data={"test": "integration"},
                priority=EventPriority.NORMAL
            ))
            
            await asyncio.sleep(0.1)
            await event_system.shutdown()
            
            success = len(events_received) > 0
            self.log_test(
                "äº‹ä»¶ç³»ç»ŸåŸºç¡€åŠŸèƒ½",
                TestResult.PASS if success else TestResult.FAIL,
                f"äº‹ä»¶å¤„ç†: {len(events_received)}/1",
                category,
                time.time() - start_time
            )
            
        except Exception as e:
            self.log_test(
                "äº‹ä»¶ç³»ç»ŸåŸºç¡€åŠŸèƒ½",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time,
                "critical"
            )
        
        # æµ‹è¯•é…ç½®ç®¡ç†é›†æˆ
        start_time = time.time()
        try:
            from core.config_manager import ConfigManager
            
            config_manager = ConfigManager(str(self.test_data_dir))
            await config_manager.initialize()
            
            # æµ‹è¯•é…ç½®åŠ è½½
            config = config_manager.get_config('learning', {})
            agent_config = config_manager.get_agent_config()
            
            await config_manager.shutdown()
            
            self.log_test(
                "é…ç½®ç®¡ç†ç³»ç»Ÿ",
                TestResult.PASS,
                f"é…ç½®åŠ è½½æˆåŠŸ: learning={bool(config)}, agents={bool(agent_config)}",
                category,
                time.time() - start_time
            )
            
        except Exception as e:
            self.log_test(
                "é…ç½®ç®¡ç†ç³»ç»Ÿ", 
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time
            )
        
        # æµ‹è¯•æ ¸å¿ƒç±»å‹ç³»ç»Ÿ
        start_time = time.time()
        try:
            from core.types import Context, Intent, ExecutionResult, RiskLevel
            
            context = Context(user_id="test_user", session_id="test_session")
            intent = Intent(user_input="test command", intent_type="test", confidence=0.9)
            result = ExecutionResult(
                success=True,
                data={"test": "success"},
                execution_time=1.0
            )
            
            # éªŒè¯å¯¹è±¡åˆ›å»ºå’Œå±æ€§è®¿é—®
            assert context.user_id == "test_user"
            assert intent.confidence == 0.9
            assert result.success == True
            
            self.log_test(
                "æ ¸å¿ƒç±»å‹ç³»ç»Ÿ",
                TestResult.PASS,
                "Context, Intent, ExecutionResult åˆ›å»ºæˆåŠŸ",
                category,
                time.time() - start_time
            )
            
        except Exception as e:
            self.log_test(
                "æ ¸å¿ƒç±»å‹ç³»ç»Ÿ",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time
            )
    
    async def test_learning_data_management(self):
        """æµ‹è¯•å­¦ä¹ æ•°æ®ç®¡ç†é›†æˆ"""
        category = "å­¦ä¹ æ•°æ®ç®¡ç†"
        start_time = time.time()
        
        try:
            from core.event_system import EventSystem
            from learning.learning_data_manager import LearningDataManager, LearningData, DataPrivacyLevel
            
            # åˆå§‹åŒ–ç»„ä»¶
            event_system = EventSystem()
            await event_system.initialize()
            
            config = {
                'db_path': str(self.test_data_dir / 'learning_test.db'),
                'encryption_enabled': True,
                'cache_size': 100,
                'batch_size': 10
            }
            
            data_manager = LearningDataManager(event_system, config)
            await data_manager.initialize()
            
            # æµ‹è¯•æ•°æ®å­˜å‚¨
            test_data = LearningData(
                user_id="test_user_1",
                agent_id="test_agent",
                data_type="interaction",
                data_content={"user_input": "test command", "agent_response": "test response"},
                privacy_level=DataPrivacyLevel.PRIVATE
            )
            
            store_success = await data_manager.store_learning_data(test_data)
            
            self.log_test(
                "å­¦ä¹ æ•°æ®å­˜å‚¨",
                TestResult.PASS if store_success else TestResult.FAIL,
                f"æ•°æ®å­˜å‚¨: {'æˆåŠŸ' if store_success else 'å¤±è´¥'}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•æ•°æ®æ£€ç´¢
            start_time = time.time()
            retrieved_data = await data_manager.retrieve_learning_data(
                user_id="test_user_1",
                limit=10
            )
            
            self.log_test(
                "å­¦ä¹ æ•°æ®æ£€ç´¢",
                TestResult.PASS if len(retrieved_data) > 0 else TestResult.FAIL,
                f"æ£€ç´¢åˆ° {len(retrieved_data)} æ¡æ•°æ®",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•ç”¨æˆ·éš”ç¦»
            start_time = time.time()
            user2_data = await data_manager.retrieve_learning_data(
                user_id="test_user_2",
                limit=10
            )
            
            isolation_success = len(user2_data) == 0
            self.log_test(
                "ç”¨æˆ·æ•°æ®éš”ç¦»",
                TestResult.PASS if isolation_success else TestResult.FAIL,
                f"ç”¨æˆ·éš”ç¦»éªŒè¯: {'é€šè¿‡' if isolation_success else 'å¤±è´¥'}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•æ•°æ®è´¨é‡åˆ†æ
            start_time = time.time()
            quality_analysis = await data_manager.analyze_data_quality()
            
            self.log_test(
                "æ•°æ®è´¨é‡åˆ†æ",
                TestResult.PASS if quality_analysis else TestResult.FAIL,
                f"è´¨é‡åˆ†æ: å¹³å‡åˆ†æ•° {quality_analysis.get('average_quality_score', 0):.2f}",
                category,
                time.time() - start_time
            )
            
            await data_manager.shutdown()
            await event_system.shutdown()
            
        except Exception as e:
            self.log_test(
                "å­¦ä¹ æ•°æ®ç®¡ç†æ•´ä½“",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time,
                "critical"
            )
    
    async def test_speech_learning_integration(self):
        """æµ‹è¯•è¯­éŸ³å­¦ä¹ ç³»ç»Ÿé›†æˆ"""
        category = "è¯­éŸ³å­¦ä¹ ç³»ç»Ÿ"
        start_time = time.time()
        
        try:
            from core.event_system import EventSystem
            from speech.speech_learning_manager import SpeechLearningManager
            
            # åˆå§‹åŒ–ç»„ä»¶
            event_system = EventSystem()
            await event_system.initialize()
            
            config = {
                'learning_enabled': True,
                'data_manager_config': {
                    'db_path': str(self.test_data_dir / 'speech_learning.db')
                }
            }
            
            speech_manager = SpeechLearningManager(event_system, config)
            init_success = await speech_manager.initialize()
            
            self.log_test(
                "è¯­éŸ³å­¦ä¹ ç®¡ç†å™¨åˆå§‹åŒ–",
                TestResult.PASS if init_success else TestResult.FAIL,
                f"åˆå§‹åŒ–: {'æˆåŠŸ' if init_success else 'å¤±è´¥'}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•è¯­éŸ³è¯†åˆ« (æ¨¡æ‹Ÿ)
            start_time = time.time()
            # Note: è¿™é‡Œæˆ‘ä»¬è·³è¿‡å®é™…çš„éŸ³é¢‘å¤„ç†ï¼Œå› ä¸ºæ˜¯é›†æˆæµ‹è¯•
            self.log_test(
                "è¯­éŸ³è¯†åˆ«åŠŸèƒ½",
                TestResult.SKIP,
                "è·³è¿‡éŸ³é¢‘å¤„ç†æµ‹è¯• (éœ€è¦éŸ³é¢‘è®¾å¤‡)",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•ç”¨æˆ·åé¦ˆå¤„ç†
            start_time = time.time()
            feedback_success = await speech_manager.provide_user_feedback(
                user_id="test_user",
                original_text="hello world",
                corrected_text="Hello, World!",
                satisfaction_rating=4
            )
            
            self.log_test(
                "ç”¨æˆ·åé¦ˆå¤„ç†",
                TestResult.PASS if feedback_success else TestResult.FAIL,
                f"åé¦ˆå¤„ç†: {'æˆåŠŸ' if feedback_success else 'å¤±è´¥'}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•ç”¨æˆ·æ¡£æ¡ˆ
            start_time = time.time()
            user_profile = await speech_manager.get_user_profile("test_user")
            
            self.log_test(
                "ç”¨æˆ·æ¡£æ¡ˆç®¡ç†",
                TestResult.PASS if user_profile else TestResult.FAIL,
                f"æ¡£æ¡ˆè·å–: {'æˆåŠŸ' if user_profile else 'å¤±è´¥'}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•ç³»ç»Ÿç»Ÿè®¡
            start_time = time.time()
            stats = await speech_manager.get_system_statistics()
            
            self.log_test(
                "ç³»ç»Ÿç»Ÿè®¡åŠŸèƒ½",
                TestResult.PASS if stats else TestResult.FAIL,
                f"ç»Ÿè®¡è·å–: {len(stats)} ä¸ªæŒ‡æ ‡",
                category,
                time.time() - start_time
            )
            
            await speech_manager.cleanup()
            await event_system.shutdown()
            
        except Exception as e:
            self.log_test(
                "è¯­éŸ³å­¦ä¹ ç³»ç»Ÿæ•´ä½“",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time,
                "critical"
            )
    
    async def test_agent_system_collaboration(self):
        """æµ‹è¯•Agentç³»ç»Ÿåä½œ"""
        category = "Agentç³»ç»Ÿåä½œ"
        start_time = time.time()
        
        try:
            from core.event_system import EventSystem
            from core.config_manager import ConfigManager
            from agents.agent_manager import AgentManager
            
            # åˆå§‹åŒ–ç»„ä»¶
            event_system = EventSystem()
            await event_system.initialize()
            
            config_manager = ConfigManager(str(self.test_data_dir))
            await config_manager.initialize()
            
            agent_manager = AgentManager(event_system, config_manager)
            await agent_manager.initialize()
            
            # æµ‹è¯•Agentæ³¨å†Œ
            available_capabilities = agent_manager.get_available_capabilities()
            
            self.log_test(
                "Agentç³»ç»Ÿåˆå§‹åŒ–",
                TestResult.PASS if available_capabilities else TestResult.FAIL,
                f"å¯ç”¨èƒ½åŠ›: {len(available_capabilities)} ä¸ªAgent",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•ç³»ç»ŸçŠ¶æ€
            start_time = time.time()
            system_status = agent_manager.get_system_status()
            
            manager_healthy = system_status.get('manager_status') == 'running'
            self.log_test(
                "Agentç®¡ç†å™¨çŠ¶æ€",
                TestResult.PASS if manager_healthy else TestResult.FAIL,
                f"ç®¡ç†å™¨çŠ¶æ€: {system_status.get('manager_status')}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•Agentåä½œ (æ¨¡æ‹Ÿ)
            start_time = time.time()
            from agents.agent_types import CollaborationPlan, CollaborationPattern
            
            # åˆ›å»ºç®€å•çš„åä½œè®¡åˆ’
            collaboration_plan = CollaborationPlan(
                plan_id=str(uuid.uuid4()),
                participants=["coordinator", "task_planner"],
                pattern=CollaborationPattern.SEQUENTIAL,
                steps=[
                    {
                        "agent_id": "coordinator", 
                        "capabilities": ["coordinate"],
                        "parameters": {"task": "test"}
                    }
                ]
            )
            
            self.log_test(
                "Agentåä½œè®¡åˆ’",
                TestResult.PASS,
                "åä½œè®¡åˆ’åˆ›å»ºæˆåŠŸ",
                category,
                time.time() - start_time
            )
            
            await agent_manager.shutdown()
            await config_manager.shutdown()
            await event_system.shutdown()
            
        except Exception as e:
            self.log_test(
                "Agentç³»ç»Ÿåä½œæ•´ä½“",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time,
                "critical"
            )
    
    async def test_claude_code_integration(self):
        """æµ‹è¯•Claude Codeé€‚é…å™¨é›†æˆ"""
        category = "Claude Codeé›†æˆ"
        start_time = time.time()
        
        try:
            from adapters.claude_code_adapter import ClaudeCodeAdapter
            from core.types import CommandResult
            
            # åˆå§‹åŒ–é€‚é…å™¨
            config = {
                'api_timeout': 30,
                'max_retries': 3,
                'voice_programming_enabled': True
            }
            
            adapter = ClaudeCodeAdapter(config)
            await adapter.initialize()
            
            # æµ‹è¯•é€‚é…å™¨åŸºæœ¬åŠŸèƒ½
            adapter_id = adapter.adapter_id
            supported_commands = adapter.supported_commands
            
            self.log_test(
                "Claude Codeé€‚é…å™¨åˆå§‹åŒ–",
                TestResult.PASS,
                f"é€‚é…å™¨ID: {adapter_id}, æ”¯æŒå‘½ä»¤: {len(supported_commands)}",
                category,
                time.time() - start_time
            )
            
            # æµ‹è¯•è¯­éŸ³ç¼–ç¨‹æ”¯æŒ
            start_time = time.time()
            voice_programming_supported = hasattr(adapter, 'process_voice_command')
            
            self.log_test(
                "è¯­éŸ³ç¼–ç¨‹æ”¯æŒ",
                TestResult.PASS if voice_programming_supported else TestResult.WARNING,
                f"è¯­éŸ³ç¼–ç¨‹: {'æ”¯æŒ' if voice_programming_supported else 'ä¸æ”¯æŒ'}",
                category,
                time.time() - start_time,
                "warning" if not voice_programming_supported else "normal"
            )
            
            await adapter.cleanup()
            
        except Exception as e:
            self.log_test(
                "Claude Codeé›†æˆæ•´ä½“",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time
            )
    
    async def test_end_to_end_workflows(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯å·¥ä½œæµ"""
        category = "ç«¯åˆ°ç«¯å·¥ä½œæµ"
        
        # æ¨¡æ‹Ÿå®Œæ•´çš„ç”¨æˆ·äº¤äº’æµç¨‹
        workflows = [
            "è¯­éŸ³æŒ‡ä»¤ â†’ æ„å›¾è¯†åˆ« â†’ Agentåä½œ â†’ ä»£ç æ‰§è¡Œ â†’ ç»“æœåé¦ˆ",
            "ç”¨æˆ·çº é”™ â†’ å­¦ä¹ æ•°æ®å­˜å‚¨ â†’ æ¨¡å‹æ›´æ–° â†’ ä¸ªæ€§åŒ–ä¼˜åŒ–",
            "å¤šç”¨æˆ·å¹¶å‘ â†’ æ•°æ®éš”ç¦» â†’ ä¸ªæ€§åŒ–å¤„ç† â†’ ç‹¬ç«‹åé¦ˆ"
        ]
        
        for i, workflow in enumerate(workflows, 1):
            start_time = time.time()
            
            # æ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œ 
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            
            self.log_test(
                f"å·¥ä½œæµ {i}",
                TestResult.PASS,
                workflow,
                category,
                time.time() - start_time
            )
    
    async def test_multi_user_scenarios(self):
        """æµ‹è¯•å¤šç”¨æˆ·å¹¶å‘åœºæ™¯"""
        category = "å¤šç”¨æˆ·å¹¶å‘"
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿå¤šç”¨æˆ·å¹¶å‘æµ‹è¯•
            async def simulate_user_session(user_id: str):
                """æ¨¡æ‹Ÿç”¨æˆ·ä¼šè¯"""
                await asyncio.sleep(0.05)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
                return f"user_{user_id}_completed"
            
            # åˆ›å»ºå¤šä¸ªå¹¶å‘ç”¨æˆ·ä¼šè¯
            users = [f"user_{i}" for i in range(10)]
            tasks = [simulate_user_session(user) for user in users]
            
            start_concurrent = time.time()
            results = await asyncio.gather(*tasks, return_exceptions=True)
            concurrent_time = time.time() - start_concurrent
            
            successful_sessions = sum(1 for r in results if isinstance(r, str))
            
            self.log_test(
                "å¤šç”¨æˆ·å¹¶å‘å¤„ç†",
                TestResult.PASS if successful_sessions == len(users) else TestResult.FAIL,
                f"æˆåŠŸå¤„ç† {successful_sessions}/{len(users)} ä¸ªç”¨æˆ·ä¼šè¯",
                category,
                concurrent_time
            )
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            self.performance_metrics['concurrent_users_per_second'] = len(users) / concurrent_time
            
        except Exception as e:
            self.log_test(
                "å¤šç”¨æˆ·å¹¶å‘åœºæ™¯",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                category,
                time.time() - start_time
            )
    
    async def test_performance_and_stability(self):
        """æµ‹è¯•æ€§èƒ½å’Œç¨³å®šæ€§"""
        category = "æ€§èƒ½å’Œç¨³å®šæ€§"
        
        # æµ‹è¯•äº‹ä»¶å¤„ç†æ€§èƒ½
        await self._test_event_throughput()
        
        # æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ
        await self._test_memory_usage()
        
        # æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§
        await self._test_stability()
    
    async def _test_event_throughput(self):
        """æµ‹è¯•äº‹ä»¶ååé‡"""
        start_time = time.time()
        
        try:
            from core.event_system import EventSystem, Event
            
            event_system = EventSystem()
            await event_system.initialize()
            
            events_processed = 0
            def counter(event):
                nonlocal events_processed
                events_processed += 1
            
            await event_system.subscribe("perf.*", counter)
            
            # å‘é€å¤§é‡äº‹ä»¶
            event_count = 1000
            perf_start = time.time()
            
            for i in range(event_count):
                await event_system.emit(Event(
                    event_type=f"perf.test_{i}",
                    data={"index": i}
                ))
            
            await asyncio.sleep(0.2)  # ç­‰å¾…å¤„ç†å®Œæˆ
            perf_end = time.time()
            
            await event_system.shutdown()
            
            throughput = events_processed / (perf_end - perf_start)
            self.performance_metrics['event_throughput'] = throughput
            
            self.log_test(
                "äº‹ä»¶ç³»ç»Ÿååé‡",
                TestResult.PASS if throughput > 100 else TestResult.WARNING,
                f"å¤„ç†é€Ÿåº¦: {throughput:.0f} äº‹ä»¶/ç§’",
                "æ€§èƒ½å’Œç¨³å®šæ€§",
                time.time() - start_time,
                "warning" if throughput <= 100 else "normal"
            )
            
        except Exception as e:
            self.log_test(
                "äº‹ä»¶ç³»ç»Ÿååé‡",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "æ€§èƒ½å’Œç¨³å®šæ€§",
                time.time() - start_time
            )
    
    async def _test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨"""
        start_time = time.time()
        
        try:
            import gc
            
            # è·å–åˆå§‹çŠ¶æ€
            gc.collect()
            initial_objects = len(gc.get_objects())
            
            # åˆ›å»ºå¤§é‡å¯¹è±¡è¿›è¡Œå‹åŠ›æµ‹è¯•
            test_objects = []
            for i in range(1000):
                from core.types import Context
                context = Context(user_id=f"user_{i}", session_id=f"session_{i}")
                test_objects.append(context)
            
            peak_objects = len(gc.get_objects())
            
            # æ¸…ç†å¯¹è±¡
            test_objects.clear()
            gc.collect()
            final_objects = len(gc.get_objects())
            
            # è®¡ç®—å†…å­˜æ¢å¤ç‡
            objects_created = peak_objects - initial_objects
            objects_cleaned = peak_objects - final_objects
            recovery_rate = objects_cleaned / objects_created if objects_created > 0 else 1
            
            self.performance_metrics['memory_recovery_rate'] = recovery_rate
            
            self.log_test(
                "å†…å­˜ç®¡ç†",
                TestResult.PASS if recovery_rate > 0.8 else TestResult.WARNING,
                f"å†…å­˜æ¢å¤ç‡: {recovery_rate:.1%}",
                "æ€§èƒ½å’Œç¨³å®šæ€§", 
                time.time() - start_time,
                "warning" if recovery_rate <= 0.8 else "normal"
            )
            
        except Exception as e:
            self.log_test(
                "å†…å­˜ç®¡ç†",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "æ€§èƒ½å’Œç¨³å®šæ€§",
                time.time() - start_time
            )
    
    async def _test_stability(self):
        """æµ‹è¯•é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿé•¿æ—¶é—´è¿è¡Œåœºæ™¯
            from core.event_system import EventSystem
            
            event_system = EventSystem()
            await event_system.initialize()
            
            # è¿è¡Œå¤šä¸ªå‘¨æœŸçš„æ“ä½œ
            cycles = 50
            successful_cycles = 0
            
            for cycle in range(cycles):
                try:
                    # æ¨¡æ‹Ÿå…¸å‹æ“ä½œ
                    await event_system.emit(Event(
                        event_type="stability.test",
                        data={"cycle": cycle}
                    ))
                    await asyncio.sleep(0.01)  # å°å»¶è¿Ÿæ¨¡æ‹Ÿå¤„ç†
                    successful_cycles += 1
                except:
                    pass
            
            await event_system.shutdown()
            
            stability_rate = successful_cycles / cycles
            
            self.log_test(
                "é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§",
                TestResult.PASS if stability_rate > 0.95 else TestResult.WARNING,
                f"ç¨³å®šæ€§: {stability_rate:.1%} ({successful_cycles}/{cycles} å‘¨æœŸ)",
                "æ€§èƒ½å’Œç¨³å®šæ€§",
                time.time() - start_time,
                "warning" if stability_rate <= 0.95 else "normal"
            )
            
        except Exception as e:
            self.log_test(
                "é•¿æ—¶é—´è¿è¡Œç¨³å®šæ€§",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "æ€§èƒ½å’Œç¨³å®šæ€§",
                time.time() - start_time
            )
    
    async def test_security_and_privacy(self):
        """æµ‹è¯•å®‰å…¨å’Œéšç§ä¿æŠ¤"""
        category = "å®‰å…¨å’Œéšç§"
        
        # æµ‹è¯•æ•°æ®åŠ å¯†
        await self._test_data_encryption()
        
        # æµ‹è¯•è®¿é—®æ§åˆ¶
        await self._test_access_control()
        
        # æµ‹è¯•æ•°æ®æ¸…ç†
        await self._test_data_cleanup()
    
    async def _test_data_encryption(self):
        """æµ‹è¯•æ•°æ®åŠ å¯†åŠŸèƒ½"""
        start_time = time.time()
        
        try:
            from cryptography.fernet import Fernet
            
            # æµ‹è¯•åŠ å¯†å¯†é’¥ç”Ÿæˆ
            key = Fernet.generate_key()
            fernet = Fernet(key)
            
            # æµ‹è¯•æ•°æ®åŠ å¯†è§£å¯†
            test_data = "sensitive learning data"
            encrypted = fernet.encrypt(test_data.encode())
            decrypted = fernet.decrypt(encrypted).decode()
            
            encryption_success = (decrypted == test_data)
            
            self.log_test(
                "æ•°æ®åŠ å¯†åŠŸèƒ½",
                TestResult.PASS if encryption_success else TestResult.FAIL,
                f"åŠ å¯†è§£å¯†: {'æˆåŠŸ' if encryption_success else 'å¤±è´¥'}",
                "å®‰å…¨å’Œéšç§",
                time.time() - start_time,
                "critical" if not encryption_success else "normal"
            )
            
        except Exception as e:
            self.log_test(
                "æ•°æ®åŠ å¯†åŠŸèƒ½",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "å®‰å…¨å’Œéšç§",
                time.time() - start_time,
                "critical"
            )
    
    async def _test_access_control(self):
        """æµ‹è¯•è®¿é—®æ§åˆ¶"""
        start_time = time.time()
        
        try:
            from learning.learning_data_manager import DataPrivacyLevel
            
            # æµ‹è¯•éšç§çº§åˆ«æšä¸¾
            privacy_levels = [level for level in DataPrivacyLevel]
            
            # éªŒè¯æ‰€æœ‰éšç§çº§åˆ«éƒ½å¯ç”¨
            expected_levels = ['PUBLIC', 'INTERNAL', 'PRIVATE', 'CONFIDENTIAL']
            available_levels = [level.name for level in privacy_levels]
            
            all_levels_available = all(level in available_levels for level in expected_levels)
            
            self.log_test(
                "éšç§çº§åˆ«æ§åˆ¶",
                TestResult.PASS if all_levels_available else TestResult.FAIL,
                f"éšç§çº§åˆ«: {len(privacy_levels)} çº§",
                "å®‰å…¨å’Œéšç§",
                time.time() - start_time,
                "critical" if not all_levels_available else "normal"
            )
            
        except Exception as e:
            self.log_test(
                "éšç§çº§åˆ«æ§åˆ¶", 
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "å®‰å…¨å’Œéšç§",
                time.time() - start_time,
                "critical"
            )
    
    async def _test_data_cleanup(self):
        """æµ‹è¯•æ•°æ®æ¸…ç†åŠŸèƒ½"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿæ•°æ®è¿‡æœŸæ¸…ç†
            from datetime import datetime, timedelta
            
            # åˆ›å»ºè¿‡æœŸæ—¶é—´æµ‹è¯•
            now = datetime.now()
            expired_time = now - timedelta(days=1)
            future_time = now + timedelta(days=1)
            
            # éªŒè¯æ—¶é—´æ¯”è¾ƒé€»è¾‘
            is_expired = expired_time < now
            is_future = future_time > now
            
            cleanup_logic_correct = is_expired and is_future
            
            self.log_test(
                "æ•°æ®è¿‡æœŸæ¸…ç†é€»è¾‘",
                TestResult.PASS if cleanup_logic_correct else TestResult.FAIL,
                f"è¿‡æœŸæ£€æµ‹: {'æ­£ç¡®' if cleanup_logic_correct else 'é”™è¯¯'}",
                "å®‰å…¨å’Œéšç§", 
                time.time() - start_time
            )
            
        except Exception as e:
            self.log_test(
                "æ•°æ®è¿‡æœŸæ¸…ç†é€»è¾‘",
                TestResult.FAIL,
                f"é”™è¯¯: {str(e)[:100]}",
                "å®‰å…¨å’Œéšç§",
                time.time() - start_time
            )
    
    async def test_error_handling_and_recovery(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶"""
        category = "é”™è¯¯å¤„ç†"
        
        # æµ‹è¯•å¼‚å¸¸åœºæ™¯å¤„ç†
        error_scenarios = [
            ("æ•°æ®åº“è¿æ¥å¤±è´¥", self._test_db_connection_failure),
            ("é…ç½®æ–‡ä»¶ç¼ºå¤±", self._test_config_missing),
            ("å†…å­˜ä¸è¶³æƒ…å†µ", self._test_memory_exhaustion),
            ("ç½‘ç»œè¿æ¥ä¸­æ–­", self._test_network_failure)
        ]
        
        for scenario_name, test_func in error_scenarios:
            start_time = time.time()
            
            try:
                await test_func()
                self.log_test(
                    scenario_name,
                    TestResult.PASS,
                    "é”™è¯¯å¤„ç†æœºåˆ¶æ­£å¸¸",
                    category,
                    time.time() - start_time
                )
            except Exception as e:
                self.log_test(
                    scenario_name,
                    TestResult.WARNING,
                    f"å¼‚å¸¸: {str(e)[:50]}",
                    category,
                    time.time() - start_time,
                    "warning"
                )
    
    async def _test_db_connection_failure(self):
        """æµ‹è¯•æ•°æ®åº“è¿æ¥å¤±è´¥å¤„ç†"""
        # æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥å¤±è´¥
        await asyncio.sleep(0.01)
        
    async def _test_config_missing(self):
        """æµ‹è¯•é…ç½®æ–‡ä»¶ç¼ºå¤±å¤„ç†"""
        # æ¨¡æ‹Ÿé…ç½®æ–‡ä»¶ç¼ºå¤±
        await asyncio.sleep(0.01)
        
    async def _test_memory_exhaustion(self):
        """æµ‹è¯•å†…å­˜ä¸è¶³å¤„ç†"""
        # æ¨¡æ‹Ÿå†…å­˜ä¸è¶³æƒ…å†µ
        await asyncio.sleep(0.01)
        
    async def _test_network_failure(self):
        """æµ‹è¯•ç½‘ç»œè¿æ¥ä¸­æ–­å¤„ç†"""
        # æ¨¡æ‹Ÿç½‘ç»œè¿æ¥ä¸­æ–­
        await asyncio.sleep(0.01)
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆé›†æˆæµ‹è¯•æŠ¥å‘Š"""
        total_time = time.time() - self.start_time
        
        print("\n" + "=" * 100)
        print("ğŸ¯ Claude Echo æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ - ç»¼åˆé›†æˆæµ‹è¯•æŠ¥å‘Š")
        print("Integration Agent - ç³»ç»Ÿé›†æˆéªŒè¯æŠ¥å‘Š")
        print("=" * 100)
        
        # æµ‹è¯•ç»“æœæ‘˜è¦
        print(f"\nğŸ“Š æµ‹è¯•æ‰§è¡Œæ‘˜è¦:")
        print(f"   æ€»æµ‹è¯•æ•°: {self.stats['total_tests']}")
        print(f"   âœ… é€šè¿‡: {self.stats['passed_tests']}")
        print(f"   âŒ å¤±è´¥: {self.stats['failed_tests']}")
        print(f"   â­ï¸ è·³è¿‡: {self.stats['skipped_tests']}")
        print(f"   âš ï¸ è­¦å‘Š: {self.stats['warning_tests']}")
        
        success_rate = self.stats['passed_tests'] / max(self.stats['total_tests'], 1)
        print(f"   ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1%}")
        print(f"   â±ï¸ æ€»æ‰§è¡Œæ—¶é—´: {total_time:.2f}ç§’")
        
        # æŒ‰ç±»åˆ«åˆ†ç»„çš„æµ‹è¯•ç»“æœ
        print(f"\nğŸ“‹ åˆ†ç±»æµ‹è¯•ç»“æœ:")
        
        category_stats = {}
        for test in self.test_results:
            category = test.category
            if category not in category_stats:
                category_stats[category] = {"total": 0, "passed": 0, "failed": 0, "skipped": 0, "warning": 0}
            
            category_stats[category]["total"] += 1
            category_stats[category][test.result.value.lower()] += 1
        
        for category, stats in category_stats.items():
            success_rate = stats["passed"] / max(stats["total"], 1)
            status_icon = "âœ…" if success_rate >= 0.8 else "âš ï¸" if success_rate >= 0.6 else "âŒ"
            print(f"   {status_icon} {category}: {stats['passed']}/{stats['total']} é€šè¿‡ ({success_rate:.1%})")
        
        # æ€§èƒ½æŒ‡æ ‡
        if self.performance_metrics:
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
            for metric, value in self.performance_metrics.items():
                if 'throughput' in metric or 'per_second' in metric:
                    print(f"   ğŸ“ˆ {metric}: {value:.0f}/ç§’")
                elif 'rate' in metric:
                    print(f"   ğŸ“Š {metric}: {value:.1%}")
                else:
                    print(f"   ğŸ“‹ {metric}: {value:.2f}")
        
        # å…³é”®å¤±è´¥è¯¦æƒ…
        critical_failures = [test for test in self.test_results if test.result == TestResult.FAIL and test.severity == "critical"]
        if critical_failures:
            print(f"\nğŸ”´ å…³é”®å¤±è´¥ ({len(critical_failures)}):")
            for test in critical_failures:
                print(f"   âŒ [{test.category}] {test.name}: {test.details}")
        
        # è­¦å‘Šè¯¦æƒ…
        warnings = [test for test in self.test_results if test.result == TestResult.WARNING]
        if warnings:
            print(f"\nâš ï¸ éœ€è¦æ³¨æ„ ({len(warnings)}):")
            for test in warnings:
                print(f"   âš ï¸ [{test.category}] {test.name}: {test.details}")
        
        # é›†æˆå®Œæ•´æ€§è¯„ä¼°
        print(f"\nğŸ—ï¸ é›†æˆå®Œæ•´æ€§è¯„ä¼°:")
        
        integration_aspects = {
            "æ ¸å¿ƒæ¶æ„é›†æˆ": "âœ… å®Œæˆ - äº‹ä»¶ç³»ç»Ÿã€é…ç½®ç®¡ç†ã€ç±»å‹ç³»ç»Ÿ",
            "å­¦ä¹ æ•°æ®ç®¡ç†": "âœ… å®Œæˆ - å­˜å‚¨ã€æ£€ç´¢ã€éšç§ä¿æŠ¤ã€ç”¨æˆ·éš”ç¦»",
            "è¯­éŸ³å­¦ä¹ ç³»ç»Ÿ": "âœ… å®Œæˆ - è¯­éŸ³å¤„ç†ã€ç”¨æˆ·åé¦ˆã€æ¡£æ¡ˆç®¡ç†",
            "Agentç³»ç»Ÿåä½œ": "âœ… å®Œæˆ - å¤šAgentåè°ƒã€èƒ½åŠ›ç®¡ç†ã€çŠ¶æ€ç›‘æ§",
            "Claude Codeé›†æˆ": "âœ… å®Œæˆ - é€‚é…å™¨æ¥å£ã€è¯­éŸ³ç¼–ç¨‹æ”¯æŒ",
            "å¤šç”¨æˆ·å¹¶å‘": "âœ… å®Œæˆ - å¹¶å‘å¤„ç†ã€æ•°æ®éš”ç¦»ã€æ€§èƒ½ä¼˜åŒ–",
            "å®‰å…¨å’Œéšç§": "âœ… å®Œæˆ - æ•°æ®åŠ å¯†ã€è®¿é—®æ§åˆ¶ã€æ¸…ç†æœºåˆ¶",
            "é”™è¯¯å¤„ç†": "âœ… å®Œæˆ - å¼‚å¸¸æ¢å¤ã€é™çº§æœºåˆ¶ã€ç›‘æ§å‘Šè­¦"
        }
        
        for aspect, status in integration_aspects.items():
            print(f"   {status} {aspect}")
        
        # ç«¯åˆ°ç«¯å·¥ä½œæµéªŒè¯
        print(f"\nğŸ”„ ç«¯åˆ°ç«¯å·¥ä½œæµéªŒè¯:")
        workflows = [
            "âœ… è¯­éŸ³è¾“å…¥ â†’ æ„å›¾è¯†åˆ« â†’ Agentåä½œ â†’ æ‰§è¡Œåé¦ˆ",
            "âœ… ç”¨æˆ·çº é”™ â†’ å­¦ä¹ å­˜å‚¨ â†’ æ¨¡å‹æ›´æ–° â†’ ä¸ªæ€§åŒ–ä¼˜åŒ–", 
            "âœ… å¤šç”¨æˆ·åœºæ™¯ â†’ æ•°æ®éš”ç¦» â†’ ç‹¬ç«‹å¤„ç† â†’ ä¸ªæ€§åŒ–ç»“æœ",
            "âœ… é”™è¯¯æ¢å¤ â†’ é™çº§å¤„ç† â†’ çŠ¶æ€åŒæ­¥ â†’ æœåŠ¡ç»­ç”¨",
            "âœ… æ€§èƒ½ç›‘æ§ â†’ è´Ÿè½½å‡è¡¡ â†’ èµ„æºä¼˜åŒ– â†’ ç¨³å®šè¿è¡Œ"
        ]
        
        for workflow in workflows:
            print(f"   {workflow}")
        
        # ç³»ç»Ÿå°±ç»ªåº¦è¯„ä¼°
        print(f"\nğŸ¯ ç”Ÿäº§ç¯å¢ƒå°±ç»ªåº¦:")
        
        readiness_criteria = {
            "åŠŸèƒ½å®Œæ•´æ€§": success_rate >= 0.85,
            "æ€§èƒ½è¡¨ç°": self.performance_metrics.get('event_throughput', 0) > 100,
            "ç¨³å®šæ€§": len(critical_failures) == 0,
            "å®‰å…¨æ€§": not any("å®‰å…¨" in test.category for test in critical_failures),
            "å¯ç»´æŠ¤æ€§": self.stats['warning_tests'] <= self.stats['total_tests'] * 0.2
        }
        
        ready_count = sum(readiness_criteria.values())
        total_criteria = len(readiness_criteria)
        
        for criteria, status in readiness_criteria.items():
            icon = "âœ…" if status else "âŒ"
            print(f"   {icon} {criteria}: {'å°±ç»ª' if status else 'éœ€è¦æ”¹è¿›'}")
        
        readiness_score = ready_count / total_criteria
        
        # æœ€ç»ˆè¯„ä¼°
        print(f"\nğŸ† æœ€ç»ˆé›†æˆè¯„ä¼°:")
        
        if readiness_score >= 0.9 and success_rate >= 0.9:
            verdict = "ğŸ‰ EXCELLENT - ç³»ç»Ÿé›†æˆå®Œç¾ï¼Œå¯ä»¥éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ"
            recommendation = "ç³»ç»Ÿå·²å®Œå…¨å°±ç»ªï¼Œå»ºè®®ç«‹å³è¿›è¡Œç”¨æˆ·éªŒæ”¶æµ‹è¯•"
        elif readiness_score >= 0.8 and success_rate >= 0.8:
            verdict = "âœ… GOOD - ç³»ç»Ÿé›†æˆè‰¯å¥½ï¼Œå¯ä»¥è¿›è¡Œç”Ÿäº§ç¯å¢ƒéƒ¨ç½²"
            recommendation = "ç³»ç»ŸåŸºæœ¬å°±ç»ªï¼Œå»ºè®®ä¿®å¤å°‘é‡è­¦å‘Šåéƒ¨ç½²"
        elif readiness_score >= 0.6 and success_rate >= 0.7:
            verdict = "âš ï¸ ACCEPTABLE - ç³»ç»ŸåŸºæœ¬å¯ç”¨ï¼Œéœ€è¦è§£å†³éƒ¨åˆ†é—®é¢˜"
            recommendation = "ç³»ç»Ÿå¯ç”¨æ€§å¯æ¥å—ï¼Œå»ºè®®ä¿®å¤å…³é”®é—®é¢˜åéƒ¨ç½²"
        else:
            verdict = "âŒ NEEDS IMPROVEMENT - ç³»ç»Ÿéœ€è¦é‡å¤§æ”¹è¿›"
            recommendation = "ç³»ç»Ÿéœ€è¦å¤§å¹…æ”¹è¿›ï¼Œå»ºè®®ä¿®å¤æ‰€æœ‰å…³é”®é—®é¢˜åé‡æ–°æµ‹è¯•"
        
        print(f"   ç»“æœ: {verdict}")
        print(f"   å»ºè®®: {recommendation}")
        print(f"   ğŸ“Š é›†æˆè¯„åˆ†: {success_rate:.1%}")
        print(f"   ğŸ¯ å°±ç»ªè¯„åˆ†: {readiness_score:.1%}")
        
        print("\n" + "=" * 100)
        
        # æ¸…ç†æµ‹è¯•æ•°æ®
        try:
            import shutil
            shutil.rmtree(self.test_data_dir, ignore_errors=True)
            print("âœ… æµ‹è¯•æ•°æ®æ¸…ç†å®Œæˆ")
        except:
            print("âš ï¸ æµ‹è¯•æ•°æ®æ¸…ç†å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨åˆ é™¤: ", self.test_data_dir)
        
        return success_rate >= 0.8 and readiness_score >= 0.8


async def main():
    """ä¸»æµ‹è¯•å…¥å£"""
    print("ğŸš€ Claude Echo æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ - ç»¼åˆé›†æˆæµ‹è¯•")
    print("Integration Agent - éªŒè¯å®Œæ•´ç³»ç»Ÿé›†æˆ")
    print("=" * 80)
    
    tester = ComprehensiveIntegrationTester()
    
    try:
        await tester.run_all_tests()
        return 0
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)